{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2d9394e-6a82-4daa-8f24-06af91eaeba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lower, max, when, expr\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Aug 22 Task\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87c30bc-5e85-425d-ae8b-ba83297be661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "df = spark.read.csv('complete.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad076085-2000-472e-805f-4594f73ff751",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m ranked_states \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m, row_number()\u001b[38;5;241m.\u001b[39mover(window))\n\u001b[0;32m     15\u001b[0m second_largest_state \u001b[38;5;241m=\u001b[39m ranked_states\u001b[38;5;241m.\u001b[39mfilter(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName of State / UT\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m     18\u001b[0m least_deaths_ut \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName of State / UT\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelhi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPuducherry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChandigarh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLadakh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJammu & Kashmir\u001b[39m\u001b[38;5;124m'\u001b[39m])) \\\n\u001b[0;32m     19\u001b[0m                    \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName of State / UT\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m---> 20\u001b[0m                    \u001b[38;5;241m.\u001b[39magg(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeath\u001b[39m\u001b[38;5;124m'\u001b[39m)) \\\n\u001b[0;32m     21\u001b[0m                    \u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeath\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[0;32m     22\u001b[0m                    \u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m col\n\u001b[0;32m     27\u001b[0m ratio_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeath_to_confirmed_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m, col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeath\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Confirmed cases\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Name of State / UT', lower(col('Name of State / UT')))\n",
    "\n",
    "\n",
    "day_with_max_cases = df.groupBy('Date').agg(max('Total Confirmed cases').alias('max_cases'))\n",
    "day_with_max_cases = day_with_max_cases.orderBy(col('max_cases').desc()).first()\n",
    "max_day = day_with_max_cases['Date']\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Assuming 'total_cases' column exists and represents the number of covid cases\n",
    "window = Window.orderBy(col('Total Confirmed cases').desc())\n",
    "ranked_states = df.withColumn('rank', row_number().over(window))\n",
    "second_largest_state = ranked_states.filter(col('rank') == 2).select('Name of State / UT').first()\n",
    "\n",
    "\n",
    "least_deaths_ut = df.filter(col('Name of State / UT').isin(['Delhi', 'Puducherry', 'Chandigarh', 'Ladakh', 'Jammu & Kashmir'])) \\\n",
    "                   .groupBy('Name of State / UT') \\\n",
    "                   .agg(sum('Death').alias('total_deaths')) \\\n",
    "                   .orderBy('total_deaths') \\\n",
    "                   .first()\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "ratio_df = df.withColumn('death_to_confirmed_ratio', col('total_deaths') / col('Total Confirmed cases'))\n",
    "state_with_lowest_ratio = ratio_df.orderBy('death_to_confirmed_ratio').first()\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import month, date_format\n",
    "\n",
    "# Assuming there's a 'new_recovered' column\n",
    "df = df.withColumn('month', month('Date'))\n",
    "monthly_recovered = df.groupBy('month').agg(sum('new_recovered').alias('total_recovered'))\n",
    "month_with_max_recovered = monthly_recovered.orderBy(col('total_recovered').desc()).first()\n",
    "\n",
    "# Convert month number to name\n",
    "month_mapping = {\n",
    "    1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',\n",
    "    7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'\n",
    "}\n",
    "month_name = month_mapping.get(month_with_max_recovered['month'], 'Unknown')\n",
    "\n",
    "\n",
    "print(f\"Day with maximum Covid cases: {max_day}\")\n",
    "print(f\"State with second-largest number of Covid cases: {second_largest_state['Name of State / UT']}\")\n",
    "print(f\"Union Territory with the least number of deaths: {least_deaths_ut['Name of State / UT']}\")\n",
    "print(f\"State with the lowest Death to Total Confirmed cases ratio: {state_with_lowest_ratio['Name of State / UT']}\")\n",
    "print(f\"Month with the most new recovered cases: {month_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
